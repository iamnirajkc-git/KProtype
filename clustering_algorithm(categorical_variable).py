# -*- coding: utf-8 -*-
"""Clustering algorithm(Categorical Variable).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l377bQYnCnI6j3ALGd0n1CpbdJ_aLFDz

# Perfoming clustering of customers based on RFM (Recency, frequency, Monetary) analysis.

# Clustering was done on categorical variable 'sex' in the  dataset Retail1.csv.

## Loading required libraries
"""

import pandas as pd
import numpy as np
import sklearn
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

"""## Loading dataset"""

# Load the dataset
df = pd.read_csv('Retail1.csv')
print(df.head())

#checking quantity and priceless than zero
print((df['Quantity'] <= 0).any())
print((df['UnitPrice'] <= 0).any())

#change into category
df['sex'] = df['sex'].astype('category')
#summary statistics of column Quantity and Unit Price
print(df[["Quantity", "UnitPrice"]].describe())
#Filtering Quantity and Unit Price wgreater than O.
df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]

# separate date, month, year, daysOfWeek column from InvoiceDate
df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])
df['Date'] = df['InvoiceDate'].dt.date
df['Month'] = df['InvoiceDate'].dt.month
df['Year'] = df['InvoiceDate'].dt.year
df['DayOfWeek'] = df['InvoiceDate'].dt.day_name()

# Convert the columns to the 'category' data type
df['Month'] = df['Month'].astype('category')
df['Year'] = df['Year'].astype('category')
df['DayOfWeek'] = df['DayOfWeek'].astype('category')

# Create the 'Total Sales' column
df['Total Sales'] = df['Quantity'] * df['UnitPrice']
df = df[(df['Total Sales'] > 0)]
CountrySales = pd.DataFrame(df.groupby('Country')['Total Sales'].sum()).reset_index()

# Total Sales By Month
sales = df.groupby(["Year","Month"])["Total Sales"].sum().reset_index()
sales  = sales[(sales['Total Sales'] > 0)]
import calendar
sales['Month'] = sales['Month'].apply(lambda x: calendar.month_abbr[x])
sales['Month'] = sales['Month'].astype(str)+ '' + sales ['Year'].astype(str)
sales = sales.drop("Year", axis=1)

#RFA Analysis
#Total Sales(Monetary)
df['CustomerID'] = df['CustomerID'].astype(str)
rfm_ds_m = df.groupby('CustomerID')['Total Sales'].sum()
rfm_ds_m.reset_index()
rfm_ds_m.columns = ['CustomerID', 'Total Amount']

#frequency of purchase
df['CustomerID'] = df['CustomerID'].astype(str)
rfm_ds_f = df.groupby('CustomerID')['InvoiceNo'].count()
rfm_ds_f = rfm_ds_f.reset_index()
rfm_ds_f.columns = ['CustomerID', 'Frequency']

#Recent Purchase
df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'],format='%d-%m-%Y %H:%M')
max_date = max(df['InvoiceDate'])
df['Diff'] = max_date - df['InvoiceDate']
rfm_ds_p = df.groupby('CustomerID')['Diff'].min()
rfm_ds_p = rfm_ds_p.reset_index()
rfm_ds_p.columns = ['CustomerID','Diff']
rfm_ds_p['Diff'] = rfm_ds_p['Diff'].dt.days

# Group by 'CustomerID' and aggregate 'Sex' as a list
grouped_data = df.groupby('CustomerID')['sex'].unique().reset_index()
new_sex = pd.DataFrame({'CustomerID': grouped_data['CustomerID'], 'sex': grouped_data['sex'].str[0]})

rfm_ds_final = pd.merge(rfm_ds_m,rfm_ds_f,on='CustomerID',how='inner')
rfm_ds_final = pd.merge(rfm_ds_final,rfm_ds_p,on='CustomerID',how='inner')
rfm_ds_final = pd.merge(rfm_ds_final,new_sex,on='CustomerID',how='inner')
rfm_ds_final.columns = ['CustomerID','Amount', 'Frequency', 'Recency', 'sex']
Cus_ID = rfm_ds_final['CustomerID']

# Encode the 'sex' column
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
sex=rfm_ds_final['sex']
rfm_ds_final['sex_encoded'] = encoder.fit_transform(rfm_ds_final['sex'])
#Changing into categorical
rfm_ds_final['sex_encoded'] = rfm_ds_final['sex_encoded'].astype('category')
# Access the encoded 'sex' column
sex_encoded = rfm_ds_final['sex_encoded']
sex_encoded.head()

"""# Handling outliers"""

# Handling Outliers
Q1 = rfm_ds_final.Amount.quantile(0.25)
Q3 = rfm_ds_final.Amount.quantile(0.75)
IQR = Q3 - Q1
rfm_ds_final = rfm_ds_final[(rfm_ds_final.Amount >= Q1 - 1.5*IQR) & (rfm_ds_final.Amount <= Q3 + 1.5*IQR)]

Q1 = rfm_ds_final.Recency.quantile(0.05)
Q3 = rfm_ds_final.Recency.quantile(0.95)
IQR = Q3 - Q1
rfm_ds_final = rfm_ds_final[(rfm_ds_final.Recency >= Q1 - 1.5*IQR) & (rfm_ds_final.Recency <= Q3 + 1.5*IQR)]

Q1 = rfm_ds_final.Frequency.quantile(0.05)
Q3 = rfm_ds_final.Frequency.quantile(0.95)
IQR = Q3 - Q1
rfm_ds_final = rfm_ds_final[(rfm_ds_final.Frequency >= Q1 - 1.5*IQR) & (rfm_ds_final.Frequency <= Q3 + 1.5*IQR)]
print(rfm_ds_final.head())

X = rfm_ds_final[['Amount', 'Frequency', 'Recency', 'sex_encoded']]

print(X.head())

X.info()

"""## Performing heat map for checking correlation and multicollinearity."""

#Heat Map for determing the correlation of variables.
import plotly.express as px

# Create a correlation matrix
correlation_matrix = X.corr()
# Generate heatmap using Plotly
fig = px.imshow(correlation_matrix,
                x=correlation_matrix.columns,
                y=correlation_matrix.columns)

# Display the heatmap
fig.show()

"""Heat Map is not showing sex as it is categorical variable in the above dataframe, we will sacle the variable which will change it in the float and we will perform heat map again later."""

#MinMaxScaling
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
rfm_ds_scaled = scaler.fit_transform(X)
rfm_ds_scaled = pd.DataFrame(rfm_ds_scaled)
rfm_ds_scaled.columns = ['Amount', 'Frequency', 'Recency', 'sex']
print(rfm_ds_scaled.head())

rfm_ds_scaled.info()

import plotly.express as px
import numpy as np

# Create a correlation matrix
correlation_matrix = rfm_ds_scaled.corr()

# Generate heatmap using Plotly
fig = px.imshow(correlation_matrix,
                x=correlation_matrix.columns,
                y=correlation_matrix.columns,
                zmin=-1,  # Set minimum value of color scale
                zmax=1)  # Set maximum value of color scale

# Add custom annotations to show correlation values
fig.update_layout(annotations=[
    dict(
        x=i,
        y=j,
        text=np.around(correlation_matrix.values[i][j], decimals=2),
        showarrow=False,
        font=dict(size=9),
    )
    for i in range(len(correlation_matrix.columns))
    for j in range(len(correlation_matrix.columns))
])

# Display the heatmap
fig.show()

!pip install kmodes

"""## Determing silhoute score for each clusters"""

import numpy as np
import plotly.offline as pyo
import plotly.graph_objs as go
from kmodes.kprototypes import KPrototypes
from sklearn.metrics import silhouette_score
num_clusters = list(range(2, 9))
silhouette_avg = []
# calculate cost values for each number of clusters (2 to 8)
for k in num_clusters:
    try:
        kproto = KPrototypes(n_jobs=-1, n_clusters=k, init='Huang', random_state=42)
        kproto.fit_predict(rfm_ds_scaled, categorical=[3])
        cluster_labels = kproto.labels_
        silhouette_avg.append(silhouette_score(rfm_ds_scaled, cluster_labels))
        print('Cluster initiation: {}'.format(k))
    except:
        break

trace = go.Scatter(x=num_clusters, y=silhouette_avg, mode='lines+markers', name='Silhouette Score')
data = [trace]
layout = go.Layout(title='Silhouette Curve', xaxis=dict(title='Number of Clusters'), yaxis=dict(title='Score'))
fig = go.Figure(data=data, layout=layout)
pyo.plot(fig, filename='silhouette.html')

fig.show()

"""As max silhoute score is only 0.56 which indicates that clusters are not properly seperated from each otherThe value of silhoute score ranges from 0 to 1. Here in the above graph cluster 5 have maxium silhoute score. We will perform PCA later for the dimensinal reduction.

# Lets see what will the optimal number of cluster, elbow curve shows.
"""

num_clusters = list(range(2, 9))
cost_values = []
for k in num_clusters:
    kproto = KPrototypes(n_jobs=-1, n_clusters=k, init='Huang', random_state=42)
    kproto.fit_predict(rfm_ds_scaled, categorical=[3])
    cost_values.append(kproto.cost_)
    cluster_labels = kproto.labels_
    print('Cluster initiation: {}'.format(k))
trace = go.Scatter(x=num_clusters, y=cost_values, mode='lines+markers', name='Elbow curve')
data = [trace]
layout = go.Layout(title='Elbow curve', xaxis=dict(title='Number of Clusters'), yaxis=dict(title='Cost'))
fig1 = go.Figure(data=data, layout=layout)
fig1.show()

"""# Based on the silhoutte and elbow method, the optimum number of cluster is 5. We will cluster the dataset using Kprototype clustering algorithm which is effective for categorical variables as K-means clustering is only effective for numerical continuous variable.

"""

# we set the number of clusters to 5
kproto = KPrototypes(n_jobs=-1, n_clusters=5 , init='Huang', n_init = 25, random_state=42)#n_init -number of centroid initialization
kproto.fit_predict(rfm_ds_scaled, categorical=[3])
# store cluster labels
cluster_labels = kproto.labels_
# add clusters to dataframe
#rfm_ds_scaled["cluster"] = cluster_labels

#Adding customer in the dataframe
#rfm_ds_scaled['customer'] = Cus_ID
#print(rfm_ds_scaled.head())

"""As metioned earlier, in our dataset the silhoute score in the clusters were not very high which indicate that our clusters are not seperated proeply so we will perform PCA(Pricipal component analysis to reduce the dimensions of the dataset). Lets see how it performs"""

#Cluster Exploration
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
pca_df = pca.fit_transform(rfm_ds_scaled)

explained_variance_ratio = pca.explained_variance_ratio_
print(explained_variance_ratio)

"""Principal component 1 expresses 70% and PC2 explained 22% variance of our dataset."""

print(rfm_ds_scaled.head())

import numpy as np
np.set_printoptions(suppress=True)
print(pca.components_)

pca_dataframe = pd.DataFrame(pca_df)
print(pca_dataframe.head())

print(pca_dataframe.info())

#Plotting PCA
fig = px.scatter(x=pca_df[:, 0], y=pca_df[:, 1], color=cluster_labels)
fig.show()

# add clusters to dataframe
rfm_ds_scaled["cluster"] = cluster_labels

#Adding customer in the dataframe
rfm_ds_scaled['customer'] = Cus_ID
print(rfm_ds_scaled.head())

# size of each cluster
print(rfm_ds_scaled["cluster"].value_counts())
print(rfm_ds_scaled["sex"].value_counts())

#Clusters for numeric variables
fig = px.scatter_matrix(rfm_ds_scaled,
    dimensions=['Amount', 'Frequency','Recency','customer','sex'],
    color="cluster",
    hover_data=['customer','sex'])
fig.show()

"""Cluster3 is has highest amount, frequency and low recency value as compared to others."""

#Clusters for categorical  variable
fig = px.histogram(rfm_ds_scaled, x="sex", color="cluster", barmode="group")
fig.show()

#look at stastitics
rfm_ds_scaled[rfm_ds_scaled["cluster"]==0].describe()

rfm_ds_scaled[rfm_ds_scaled["cluster"]==4].describe()

rfm_ds_scaled[rfm_ds_scaled["cluster"]==3].describe()

#Cluster3 is the best cluster among all.